#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1.2in
\rightmargin 1in
\bottommargin 1.2in
\columnsep 0.1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Mini-project Report
\end_layout

\begin_layout Author
Samuel Humeau 222974, Benyounes Moumni 179848
\end_layout

\begin_layout Abstract
The goal of this project is to implement and train a multilayer perceptron
 to classify images from the small NORB dataset.
 The dataset has 10'800 images of objects in 5 different categories: four-legged
 animals, human figures, airplanes, trucks, and cars.
 The train set contains 5400 samples while the test set contains 5400.
 In Section 1 we describe some implementation decisions and discuss the
 result for the first task (binary classification).
 We describe the implementation of the MLP for multi way classification
 in section 2.
 We conclude in section 3.
\end_layout

\begin_layout Section
Binary Classification
\end_layout

\begin_layout Standard
The first task is to implement a binary classifier using a 2-hidden layer
 perceptron with logistic error.
 the architecture of the network is described in the project description.
 We will first describe how we derived the gradient formulas then show the
 results.
 
\end_layout

\begin_layout Subsection
Normalization
\end_layout

\begin_layout Standard
We use the normalization procedure as described in the project guidelines.
 We normalize the training set and save the mean and variance.
 These values are used to normalize the validation set and test set.
 
\end_layout

\begin_layout Subsection
Early Stopping
\end_layout

\begin_layout Standard
After observing the evolution of the validation error after each epoch,
 we noticed that stopping after the validation error start increasing is
 not a good idea.
 Indeed the curve is highly variable during the first epochs.
 Instead we average the validation error over 4 epochs, that way, small
 fluctuations will be ignored.
 Since we have never observed an overfitting effect (increasing of validation
 error), we decided to stop when the improvement becomes insignificant to
 speed up the training time i.e.
 the new averaged error over 4 epochs is higher than 0.95 times the old one.
 
\begin_inset Formula $error(window)>0.95\times error(window-1)$
\end_inset

.
\end_layout

\begin_layout Subsection
Results & Discussion
\end_layout

\begin_layout Standard
We tried the classifier with several configurations of number of layers
 and learning rate.
 We found that all instances of the validation set are correctly classified
 after the first epoch with a very low error.
 It seems that the two class are very easily separable, this explains this
 good performance.
 In this case there is not much optimization possible : since a logistic
 error is used, increasing the weight of the last layer makes tend to 0,
 no matters the hyper parameters.
 Therefore we arbitrarily chose, for the following results, a learning rate
 of 0.001 and a momentum of 0.05.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename binaryerror_h1=10_h2=5_mom=0.5_learning_rate=0.001.eps
	width 100text%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
h1=10 h2=5 mom=0.05 learning_rate=0.001
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Minimum
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mean
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Standard deviation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Maximum
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.7%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3.5%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2.0%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7.5%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
Error rate on the test set with optimal parameters over 15 runs
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
New dataset
\end_layout

\begin_layout Standard
In order to verify our assumption concerning the separability of the two
 classes, we created another dataset, using the samples of truck and cars.
 The idea is that some other classes are less separable and would allow
 us to have a better idea of the performance of our implementation.
 We have not driven formally a study of it, but we observed the classification
 on the validation set is higher than in the case Truck/Figurines.
\end_layout

\begin_layout Section
Multi-way classification
\end_layout

\begin_layout Standard
In order to have elements of comparison for the multiway MLP we are going
 to implement, it is important to have other solutions as baselines.
 Indeed it is expected that a MLP outperforms all linear solutions.
 Therefore we have implemented 3 linear classifiers described in the next
 three sections.
 
\end_layout

\begin_layout Subsection
Linear regression with squared error
\end_layout

\begin_layout Standard
For this part, each datapoint belongs to one of 5 class.
 Thus, the label attributed for each datapoint is no more a scalar but a
 binary 5-dimensional vector.
 For example if 
\begin_inset Formula $x$
\end_inset

 belongs to the class number 2, its label will be 
\begin_inset Formula $\widetilde{t_{i}}=[0,1,0,0,0]$
\end_inset

.
 Let consider the classification error on the training set to be : 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{2}(W)=\sum_{i=1}^{N}\left\Vert y_{i}-\tilde{t}_{i}\right\Vert ^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
The linear classifier computes the 5-dimensional output : 
\begin_inset Formula $y_{i}=W[x_{i};1]$
\end_inset

 (we add a constant coordinate in each data points in order to incorporate
 the bias in the matrix W).
 Then the class is determined by 
\begin_inset Formula $argmax_{j}y_{i}(j)$
\end_inset

.
 In the case of the squared error above, the course shows that the matrix
 W that optimizes the regression on the training set is given by : 
\end_layout

\begin_layout Standard
\begin_inset Formula $W_{optimal}=(\Phi^{T}\Phi)^{-1}\Phi T$
\end_inset

 where 
\begin_inset Formula $\Phi$
\end_inset

 is a matrix where each column is a datapoint, and 
\begin_inset Formula $T$
\end_inset

 is the the matrix that regroup the corresponding labels.
 
\end_layout

\begin_layout Standard
By computing this classifier, we obtain 1228 misclassified elements on the
 test set (over a total of 5400 data points), which means an accuracy of
 77%.
 
\end_layout

\begin_layout Subsection
Squared error with Tichonov regularizer
\end_layout

\begin_layout Standard
\begin_inset CommandInset label
LatexCommand label
name "sub:section_tichonov"

\end_inset


\end_layout

\begin_layout Standard
A classic improvement of linear regression is to constrain the weights using
 a tichonov regularizer.
 The error is now : 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{2}(W)=\frac{1}{2}\sum_{i=1}^{N}\left\Vert y_{i}-\tilde{t}_{i}\right\Vert ^{2}+\frac{\nu}{2}\left\Vert W\right\Vert ^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
In this case, for a fixed 
\begin_inset Formula $\nu$
\end_inset

, the course gives us the optimal weights for the regression on the training
 set (using the same notation introduced above) :
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
W_{tichonov}=(\Phi^{T}\Phi+\nu I)^{-1}\Phi^{T}T
\]

\end_inset

In order to find the best regularizer 
\begin_inset Formula $\nu$
\end_inset

, we compute a 10-folds cross validation on the training set, for different
 values of 
\begin_inset Formula $\nu$
\end_inset

.
 We have selected the regularizer that minimizes the risk, which is computed
 as follow : after splitting the training set in 10 equals parts, 
\begin_inset Formula $risk=\frac{1}{10}\sum_{m=1}^{10}R^{(-m)}(W^{(-m)})$
\end_inset

, where 
\begin_inset Formula $R^{(-m)}$
\end_inset

is the error 
\begin_inset Formula $E_{2}$
\end_inset

 computed only of the 
\begin_inset Formula $m^{th}$
\end_inset

part of the classifier trained with the 9 other parts of the training set.
 
\end_layout

\begin_layout Standard
Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:tichonov_optimization"

\end_inset

 shows the evolution of the risk with 
\begin_inset Formula $\nu$
\end_inset

.
 Since minimum is obtained for 
\begin_inset Formula $\nu\approx400$
\end_inset

, we have take this value to build the regularized classifier.
 This one makes a good result on the test set, with only 817 misclassified
 elements (85% accuracy).
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename tichnov.eps
	BoundingBox 0bp 0bp 415bp 168bp

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:tichonov_optimization"

\end_inset

Evolution of the risk (defined in section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:section_tichonov"

\end_inset

) with the tichonov regularizer.
 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Logistic regression
\end_layout

\begin_layout Standard
Another improvement is to consider a logistic error : 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
E_{log}(W)=\frac{1}{2}\sum_{i=1}^{N}\mbox{lsexp}(y(x_{i}))-\tilde{t_{i}^{T}}y(x_{i})
\]

\end_inset


\end_layout

\begin_layout Standard
There is no analytic solution of this kind of error.
 We are forced to implement a gradient descent.
 The course p.
 145 gives the value of the gradient : 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\nabla_{y_{i}}E_{i}=\sigma(y_{i})-\tilde{t_{i}}=[\frac{e^{y_{i}(k)}}{\sum_{k}e^{(k)}}]_{k=1...5}
\]

\end_inset


\end_layout

\begin_layout Standard
For early stopping, we have simply taken a validation set of 1/3 of the
 whole training set.
 Early stopping is triggered whenever the error on the validation does not
 decrease significantly (
\begin_inset Formula $error(epoch)>0.95*error(epoch-1)$
\end_inset

).
 Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Optimization-logistic"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Table_resultlog"

\end_inset

 gives the result of our optimization of the learning rate, and the result
 of the optimal classifier (learning rate = 0.005) on the test set.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mu$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Averaged error on the validation set
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.9185
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.005
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1700
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.001
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.3200
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0005
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.4188
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Optimization-logistic"

\end_inset

Optimization of 
\begin_inset Formula $\mu$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mu$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mean
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Standard deviation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Minimum
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Maximum
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.005
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
19.6%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.5%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
17.2%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
22.9%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Table_resultlog"

\end_inset

Error rate on the test set over 15 runs
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Multi-Class MLP 
\end_layout

\begin_layout Subsubsection
Support for multiple classes
\end_layout

\begin_layout Standard
There are several ways to extend our binary MLP to support multiple classes.
 We can do pairwise binary classification or K one-vs-all binary classifiers
 and then have one linear layer to make a decision based on that.
 We chose however another solution which is to extend the last layer to
 support multiple classes by setting its size to K=5.
 The target values are therefore in the form 
\begin_inset Formula $t_{i}=\text{[0,0,1,0,0]}$
\end_inset

 for class 
\begin_inset Formula $k=3$
\end_inset

 for example.
 As described in the guidelines, we used a squared error for training.
\end_layout

\begin_layout Subsubsection
Hyper-parameters Search
\end_layout

\begin_layout Standard
Now that the MLP is working and the gradient has been tested, we need to
 find the optimal parameters -- namely 
\begin_inset Formula $H1,H2$
\end_inset

, learning rate (
\begin_inset Formula $\mu$
\end_inset

) and momentum (
\begin_inset Formula $\nu$
\end_inset

) .
 We run two hyper-parameters search, one for 
\begin_inset Formula $H1,H2$
\end_inset

 and one for 
\begin_inset Formula $\nu$
\end_inset

 and 
\begin_inset Formula $\mu$
\end_inset

.
 We assume naively that the sets of parameters are independent, although
 we found that it is a reasonable assumption in practice.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename h1h2.pdf
	scale 60
	rotateOrigin rightBottom

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:h1h2"

\end_inset

Hyper-parameter search for H1 and H2, 2 different values of learning rate
 and momentum.
 A.
 Shows the final error on the vaidation set B.
 Shows the number of epochs.
 The number of epochs is limited to 50 for speed of convergence reasons
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Number of neurons
\end_layout

\begin_layout Standard
The first search has been done on a small cluster of 4 nodes and 32 cores
 during 14 hours.
 The values for both H1 and H2 are 10,20,30,40,60,80,100.
 We also try two values of learning rates and momentum term to increase
 the confidence in the result.
 Moreover, we average the results for a single configuration over 3 runs.
 The results are shown in Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:h1h2"

\end_inset

.
 Based on these number we decided to select 
\begin_inset Formula $H1=60$
\end_inset

 and 
\begin_inset Formula $H2=40$
\end_inset

 .
 The difference between nearby values is relatively small and doesn't justify
 running another search around those values.
\end_layout

\begin_layout Paragraph
Learning rate and Momentum
\end_layout

\begin_layout Standard
The second search have been done on a single quad-core computer and took
 a couple of hours.
 The value that were tested are for the learning rate: 0.001,0.005,0.01,0.05
 and for the momentum: 0, 0.01, 0.05, 0.1 with H1=60, H2=40.
 The results are shown in Tableau 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Optimization-of-learning"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="5">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\mu$
\end_inset


\backslash

\begin_inset Formula $\nu$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.001
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0251
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0251
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0224
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0242
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.005
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0106
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0141
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0114
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0109
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.01
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\boldsymbol{0.0075}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0082
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0095
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0095
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.05
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0123
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0082
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0078
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.0107
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Optimization-of-learning"

\end_inset

Optimization of learning rate and momentum, with H1=60, H2=40
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Results & Discussion 
\end_layout

\begin_layout Standard
Finally our best hyper parameters were 
\begin_inset Formula $H1=60$
\end_inset

, 
\begin_inset Formula $H2=40$
\end_inset

, 
\begin_inset Formula $\mu=0.01$
\end_inset

, 
\begin_inset Formula $\nu=0$
\end_inset

.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Error-multi"

\end_inset

 shows the evolution of the error on the validation set for this case.
 The execution on the test set (Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Results-nulti_testset"

\end_inset

), has given about 90% accuracy, which beats every linear classifiers we
 have implemented.
 The confusion matrix 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:confusion"

\end_inset

 shows that some classes are similar (like truck and car, and human and
 animals).
 In some cases, depending on the point of view where the picture has been
 token, the ambiguity can be high.
 For an example, figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:A.-badclass"

\end_inset

shows one pattern that is not well classified by the binary classifier,
 and we notice that even with a human eye it is hard to determine which
 class it belongs.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename errors.eps
	width 100text%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:Error-multi"

\end_inset

Error on multi-class classification task with parameters: 
\begin_inset Formula $H1=60$
\end_inset

, 
\begin_inset Formula $H2=40$
\end_inset

, 
\begin_inset Formula $\mu=0.01$
\end_inset

, 
\begin_inset Formula $\nu=0$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename Sans titre.png
	width 80col%

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:confusion"

\end_inset

Confusion matrix on the test set with optimal parameters
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="2" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<column alignment="center" valignment="top" width="0">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Minimum
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mean
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Standard deviation
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Maximum
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9.0%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
10.7%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1.0%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
12.3%
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "tab:Results-nulti_testset"

\end_inset

Error 0/1 on the test set with optimal parameters over 15 runs
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename bad_classification.png

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:A.-badclass"

\end_inset

A.
 Large negative 
\begin_inset Formula $\boldsymbol{t}_{i}\boldsymbol{a}_{i}^{(3)}$
\end_inset

 -10 B.
 Small negative 
\begin_inset Formula $\boldsymbol{t}_{i}\boldsymbol{a}_{i}^{(3)}$
\end_inset

 -0.2 C.
 Well classified 9.8 (on the binary classifier)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard
In general we have achieved the main goal of the project which is to train
 an MLP for multiway classification of the NORB dataset.
 We have finally achieve a system that is 90% accurate, which is good and
 on par with reported results for the NORB dataset (even if recent research
 on deep learning outperforms largely any other methods).
 The project was helpful to teach us the subtlety and caveats of training
 neural networks.
 
\end_layout

\end_body
\end_document
